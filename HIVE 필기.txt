[Hive]

   1) 하둡 기반에서 실행되는 라이브러리
   2) Java 코드 대신 SQL 구문 사용 (Hive)
   3) 설치 
		- http://hive.apache.org 
      
		Downloads > 2.대 버전 
      
		http://mirror.navercorp.com/apache/hive/hive-2.3.7/
		apache-hive-2.3.7-bin.tar.gz 다운로드 
      
		*WinSCP로 옮기기 
		/root/ 폴더에
		
		
		
		- 압축 풀기 
        tar zxvf 하이브 파일명 
        mv apache-hive-2.3.7-bin hive2 
		 
		ll
		rm apache-hive~~ 		y

		gedit /etc/profile
		-------------------------------
		export HIVE_HOME=/root/hive2
		export PATH=$PATH:$HIVE_HOME/bin

		source /etc/profile

		stop-dfs.sh
		stop-yarn.sh
		reboot

		start-dfs.sh
		start-yarn.sh
		jps		// 확인

		hive		// 바뀌는지 확인
		quit;		//종료 명령어

		*WinSCP로 옮기기 
		mysql-connector을 hive2/bin 폴더에
		
		
		ll /root/hive2/conf
		
		gedit hive-site.xml
		-----------------------
		<?xml version="1.0" encoding="UTF-8" standalone="no" ?>
		<?xml-stylesheet type="text/xsl" href="configuration.xsl" ?>

		<configuration>
			  <property>
					<name>hive.metastore.local</name>
					<value>true</value>
			  </property>
			  <property>
					<name>javax.jdo.option.ConnectionURL</name>
					<value>jdbc:mysql://mysql_ip:3306/hive?useSSL=false&amp;createDatabaseIfNotExist=true&amp;serverTimezone=UTC</value>
			  </property>
			  <property>
					<name>javax.jdo.option.ConnectionDriverName</name>
					<value>com.mysql.jdbc.Driver</value>
			  </property>
			  <property>
					<name>javax.jdo.option.ConnectionUserName</name>
					<value>hive</value> 
			  </property>
			  <property>
					<name>javax.jdo.option.ConnectionPassword</name>
					<value>hive</value>
			  </property>
		</configuration>

		- mysql
            계정 생성
                  mysql -uroot -p1111;
                  create user hive@localhost identified by 'hive';
                  grant all privileges on hive.* to hive@localhost;
                  grant all privileges on *.* to 'hive'@'%' identified by 'hive';
                  flush privileges;
                  exit
                  
            DB 생성
                  mysql -uhive -phive
                  create database hive;
                  
            윈도우 방화벽 포트 개방
            
	4) MetaStore 초기화 작업
			schematool -initSchema -dbType mysql
	
	5) hdfs에 하이브 작업공간 설정
			hdfs dfs -ls -R /
			
			hdfs dfs -mkdir /user/hive
			hdfs dfs -mkdir /user/hive/warehouse
			
			(hdfs dfs -ls /tmp)
			
			hive
			
			hdfs dfs -chmod g+x /tmp
			hdfs dfs -chmod g+x /user/hive
			hdfs dfs -chmod g+x /user/hive/warehouse
			
	6) hive에 저장할 데이터 준비
		- emp.csv, dept.csv, salgrade 3개의 파일을 리눅스에 전송	
		- hive에 테이블 3개 준비
			create table dept(
				dname string,
				loc string,
				deptno int
			) row format delimited fields terminated by ',';
			
			// db가 아닌 파일로 저장되기 때문에 마지막 문장 붙여줌
			
			show tables;
			desc dept;
			
			create table emp(
				empno int,
				ename string,
				job string,
				mgr int,
				hiredate string,
				sal int,
				comm int,
				deptno int
				) row format delimited fields terminated by ',';
				
				
			create table salgrade(
				grade int,
				losal int,
				hisal int
			) row format delimited fields terminated by ',';
			
			show tables;
			
		-3개의 csv파일을 하이브 테이블로 로드
			load data local inpath '/root/source/emp.csv' overwrite into table emp;
			load data local inpath '/root/source/dept.csv' overwrite into table dept;
			load data local inpath '/root/source/salgrade.csv' overwrite into table salgrade;
			
			select * from emp;
			select * from dept;
			select * from salgrade;
			
			select d.deptno, d.dname, e.ename, e.sal from emp e, dept d where e.deptno = d.deptno;
			select d.deptno, d.dname, e.ename, e.sal from emp e, dept d where e.deptno = d.deptno and e.job like '%CLERK%';
			select deptno,count(*) cnt, sum(sal) sum_sal avg(sal), avg_sal from emp groupby deptno order by deptno;

		- 항공 운항 데이터로 실습
			create table ontime( year int, month int,  ayofmonth int, 	dayofweek int, deptime int, crsdeptime int, 	arrtime int, crsarrtime int, uniquecarrier string, flightnum int, tailnum string, actualelapsedtime int, crselapsedtime int, airtime int, arrdelay int, depdelay int, origin string, dest string, distance int, taxiin int, taxiout int, cancelled int, cancellationcode string, deverted int, carrierdelay string, weatherdelay string, nasdelay string, securitydelay string, lateaircraftdelay string)	partitioned by (delayyear int) row format delimited fields  terminated by ',' lines terminated by '\n' stored as textfile;

		- 리눅스에 있는 airline 데이터에서 각 파일의 첫번째 줄을 삭제
			cd /root/source/airline
			
			sed -e '1d' 2006.csv > 2006_new.csv	//원본에 영향없이 다른 곳에 복사를 해서 파일을 수정하고 싶을 때 sed
			sed -e '1d' 2007.csv > 2007_new.csv
			sed -e '1d' 2008.csv > 2008_new.csv
		
		-3개의 csv파일을 하이브 테이블로 로드 (hive에서)
			load data local inpath '/root/source/airline/2006_new.csv' overwrite into table ontime partition(delayyear = '2006');		//2006이라는 이름의 폴더를 만드는 것
			load data local inpath '/root/source/airline/2007_new.csv' overwrite into table ontime partition(delayyear = '2007');
			load data local inpath '/root/source/airline/2008_new.csv' overwrite into table ontime partition(delayyear = '2008');
			
			select * from ontime limit 10;		// 그냥 실행됨
			select count(*) from ontime;		// 조건이나 집계, 정렬이 붙으면 맵리듀스가 작동 됨
			
		- 출발 지연 건수
			select year,month, count(*) from ontime where depdelay>0 group by year, month order by yaer, month;
			
		- 파일목록 확인
				[root@master airline]에서
				
				hdfs dfs -ls /user/hive/warehouse/ontime
				hdfs dfs -ls /user/hive/warehouse/ontime/delayyear=2006
								
		- 도착 지연 건수
				hive> 에서
				
				select year, month, count(*) from ontime
				where arrdelay>0 group by year, month order by year, month;						
				
		- 조인 연습
				http://stat-computing.org/dataexpo/2009/supplemental-data.html 들어가서
				airports.csv carriers.csv 2개 다운 받기  //파란글씨로 써져있음
				다운받은 2개를 winSCP에서 source/airline 폴더에 업로드한다.
				
				carriers.csv 파일의 항공사 코드에서 쌍따옴표를 제거! (정규표현식 사용!)
				
				[root@master airline]에서
				
				find .-name carriers.csv -exec perl -p -i -e 's/"//g' {} \;
				cat carriers.csv  //여기서 쌍따옴표 안보이면 성공!
				(나는 그런 파일이나 디렉토리가 없다고 뜨는데 그래도 일단 지워지긴해서 그냥 하는 중!)
				
				hive> 에서

				create table carrier_code(
						code string,
						description string
				) row format delimited fields  terminated by ',' lines terminated by '\n' stored as textfile;

				load data local inpath '/root/source/airline/carriers.csv' overwrite into table carrier_code;
				
				select a.year, a.uniquecarrier, c.description, count(*) 
				from ontime a join carrier_code c 
				on a.uniquecarrier=c.code 
				where a.arrdelay > 0 
				group by a.year, a.uniquecarrier, c.description
				order by a.year, a.uniquecarrier, c.description;

			
			